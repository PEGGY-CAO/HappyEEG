{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HappyEEG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "HappyEEG is a cloud-enabled, mobile-ready, realtime EEG emotion predicting algorithm allowing marketing specialists to see how their material affects their target audience at the subconcious level. Want to know if a poster of a luxury brand spikes the Schadenfreude--responsible for jealousy-- in real-time with real-world stimuli to know how your audience react to your ad? Use HappyEEG!  \n",
    "\n",
    "  - Generalizes to new brains with short training (<20 minutes)\n",
    "  - State of the art training is performed entirely in the Google ML Engine\n",
    "  - This allows a completely mobile system to monitor emotional states virtually anywhere\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Google Cloud Platform](https://www.retailbusinesstechnologyexpo.com/__novaimages/4461286?v=636567609703630000&h=120&type=3&w=120&q=100)](https://cloud.google.com/gcp/?utm_source=google&utm_medium=cpc&utm_campaign=na-US-all-en-dr-bkws-all-all-trial-e-dr-1003905&utm_content=text-ad-none-any-DEV_c-CRE_113120492767-ADGP_Hybrid%20%7C%20AW%20SEM%20%7C%20BKWS%20%7C%20US%20%7C%20en%20%7C%20EXA%20~%20Google%20Cloud%20Platform-KWID_43700009942847400-kwd-26415313501&utm_term=KW_google%20cloud%20platform-ST_google%20cloud%20platform&gclid=CjwKCAjwx7DeBRBJEiwA9MeX_FowZwUrPoy-TiUvXPxKqlbdraEfNWZ7JTEn4HWL6TK4m2P8BNvAyBoCy8kQAvD_BwE&dclid=CJ2O1fStl94CFVMNNwodH0ED3A) \n",
    "[![Jupyter Notebooks](https://images.g2crowd.com/uploads/product/image/large_detail/large_detail_1514651055/jupyter.png)](https://cloud.google.com/gcp/?utm_source=google&utm_medium=cpc&utm_campaign=na-US-all-en-dr-bkws-all-all-trial-e-dr-1003905&utm_content=text-ad-none-any-DEV_c-CRE_113120492767-ADGP_Hybrid%20%7C%20AW%20SEM%20%7C%20BKWS%20%7C%20US%20%7C%20en%20%7C%20EXA%20~%20Google%20Cloud%20Platform-KWID_43700009942847400-kwd-26415313501&utm_term=KW_google%20cloud%20platform-ST_google%20cloud%20platform&gclid=CjwKCAjwx7DeBRBJEiwA9MeX_FowZwUrPoy-TiUvXPxKqlbdraEfNWZ7JTEn4HWL6TK4m2P8BNvAyBoCy8kQAvD_BwE&dclid=CJ2O1fStl94CFVMNNwodH0ED3A) \n",
    "[![Google Cloud Platform](https://d1q6f0aelx0por.cloudfront.net/product-logos/6bd224a8-e827-4593-b5b4-483338e9999e-python.png )](https://cloud.google.com/gcp/?utm_source=google&utm_medium=cpc&utm_campaign=na-US-all-en-dr-bkws-all-all-trial-e-dr-1003905&utm_content=text-ad-none-any-DEV_c-CRE_113120492767-ADGP_Hybrid%20%7C%20AW%20SEM%20%7C%20BKWS%20%7C%20US%20%7C%20en%20%7C%20EXA%20~%20Google%20Cloud%20Platform-KWID_43700009942847400-kwd-26415313501&utm_term=KW_google%20cloud%20platform-ST_google%20cloud%20platform&gclid=CjwKCAjwx7DeBRBJEiwA9MeX_FowZwUrPoy-TiUvXPxKqlbdraEfNWZ7JTEn4HWL6TK4m2P8BNvAyBoCy8kQAvD_BwE&dclid=CJ2O1fStl94CFVMNNwodH0ED3A)\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "Simply download the DEAP dataset from [here](http://www.eecs.qmul.ac.uk/mmv/datasets/deap/) and set-up a Google GPU-enabled Jupyter notebook in under 15 minutes per [these instructions](https://towardsdatascience.com/running-jupyter-notebook-in-google-cloud-platform-in-15-min-61e16da34d52?fbclid=IwAR1Mg-sls7VAvlhttps%3A%2F%2Fl.facebook.com%2Fl.php%3Fu%3Dhttps%3A%2F%2Ftowardsdatascience.com%2Frunning-jupyter-notebook-in-google-cloud-platform-in-15-min-61e16da34d52%3Ffbclid%3DIwAR1Mg-sls7VAvlRXOPRP7KkwWu4HfjDZ2WCIC_r9ednvIOqoYcBVWYzqrSw&h=AT2uBjVkEL0ZSw-9vN4a17BCVdArWVUQSe03JvYA_d-nVPFkp8AxUAnaZ0IrXzVydi6BJ8L6Co3VmDOH0IRdHy-QUpnXi6H_uSPIo-wIjkrjkl9dT3dN-W3Shp_YK9D72W6x40hnDdnVJWDe76NcJuwRXOPRP7KkwWu4HfjDZ2WCIC_r9ednvIOqoYcBVWYzqrSw). Then upload this very notebook to your Google VM to be running accurate valence (emotion-state) classification right away! Serve this model with Google AI Enginer to allow for online learning and connect an internet (MySQL) commercially available EEG cap to monitor your target audience's emotion state and intensity. \n",
    "\n",
    "\n",
    "## Classifing Offline: \n",
    "\n",
    "First, let's read in a entire minute of EEG data. This is a lot of time to be considered real-time, but it's a good proof-of-concept. Note that our data has already been down-sampled to 126 Hz, and trasnformed into the power domain. Implement these *in silico* for a real-time system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5a51e74eb298>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import random\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG files\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DEAP_data/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1a8bf93236e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtrain_fragments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtrain_truth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DEAP_data/\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DEAP_data/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'.dat'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Filenames are \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DEAP_data/'"
     ]
    }
   ],
   "source": [
    "\n",
    "#first, read in the pre-processed data from a folder containing the DEAP .dat files.  \n",
    "\n",
    "print(\"Loading EEG files\")\n",
    "validation_fragments = []\n",
    "validation_truth = []\n",
    "train_fragments = []\n",
    "train_truth = []\n",
    "filenames = [f for f in listdir(\"DEAP_data/\") if (isfile(join(\"DEAP_data/\", f)) and '.dat' in f)]\n",
    "print(\"Filenames are \", filenames)\n",
    "\n",
    "x_test = []\n",
    "y_test= []\n",
    "x_train = []\n",
    "y_train= []\n",
    "import _pickle as cPickle\n",
    "\n",
    "import random\n",
    "\n",
    "for filename in filenames:\n",
    "    with open(\"DEAP_data/\" + filename, 'rb') as f:\n",
    "        print(filename)\n",
    "        array = cPickle.load(f, encoding='latin1')\n",
    "        #print(\"array is\", np.array(array))\n",
    "        for datum, label in zip(list(array[\"data\"]), list(array[\"labels\"])):\n",
    "            if random.uniform(0,1) < .2:\n",
    "                x_test.append(np.array(datum).flatten())\n",
    "                y_test.append(label[0])\n",
    "            else:\n",
    "                x_train.append(np.array(datum).flatten())\n",
    "                y_train.append(label[0])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x_test, y_test, x_train, y_train = np.array(x_test), np.array(y_test), np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Load data into DMatrix object\n",
    "print(x_train.shape, \" is length\")\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dvalidation = xgb.DMatrix(x_test, label=y_test)\n",
    "\n",
    "# Train XGBoost model\n",
    "parameter_dictionary = {}\n",
    "parameter_dictionary[\"objective\"] = \"binary:logitraw\"\n",
    "parameter_dictionary[\"watchlist\"]= dvalidation\n",
    "\n",
    "clf = xgb.XGBRegressor(n_estimators=10000)\n",
    "eval_set  = [(x_train,y_train), (x_test,y_test)]\n",
    "clf.fit(x_train, y_train, eval_set=eval_set, eval_metric=\"mae\")\n",
    "# Export the classifier to a file\n",
    "model = 'model.bst'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifing Online: \n",
    "\n",
    "Now that we have some classification working, let us confirm that we can classifiy with only 3 seconds of brain-recording so that we can truly claim a real-time system! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG files\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DEAP_data/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ea17146bd8a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtrain_fragments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtrain_truth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DEAP_data/\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DEAP_data/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'.dat'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Filenames are \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DEAP_data/'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Loading EEG files\")\n",
    "validation_fragments = []\n",
    "validation_truth = []\n",
    "train_fragments = []\n",
    "train_truth = []\n",
    "filenames = [f for f in listdir(\"DEAP_data/\") if (isfile(join(\"DEAP_data/\", f)) and '.dat' in f)]\n",
    "print(\"Filenames are \", filenames)\n",
    "\n",
    "x_test = []\n",
    "y_test= []\n",
    "x_train = []\n",
    "y_train= []\n",
    "import _pickle as cPickle\n",
    "\n",
    "import random\n",
    "\n",
    "for filename in filenames:\n",
    "    with open(\"DEAP_data/\" + filename, 'rb') as f:\n",
    "        print(filename)\n",
    "        array = cPickle.load(f, encoding='latin1')\n",
    "        #print(\"array is\", np.array(array))\n",
    "        for datum, label in zip(list(array[\"data\"]), list(array[\"labels\"])):\n",
    "            numberSegments = (len(datum) % (1751))\n",
    "            markers = np.array([(1,(i)*(1751),(i+1)*(1751)-1) for i in range(numberSegments-1)]) \n",
    "            print(\"markers are \", markers)\n",
    "            for stim_code, start, end in markers:\n",
    "                stim_code, start, end = (int(stim_code), int(start), int(end))\n",
    "                #note that the Emory lab doesn't use end; all are of length 1\n",
    "                print(\"datum size is \", datum.size)\n",
    "                print(\"start is \", start)\n",
    "                fragment = datum[start:end]   \n",
    "                print(\"fragment size is \", fragment.size)\n",
    "                if not len(fragment) == 0:\n",
    "                    if random.uniform(0,1) < .8:\n",
    "                        x_test.append(np.array(fragment).flatten())\n",
    "                        y_test.append(label[0])\n",
    "                    else:\n",
    "                        x_train.append(np.array(fragment).flatten())\n",
    "                        y_train.append(label[0])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "x_test, y_test, x_train, y_train = np.array(x_test), np.array(y_test), np.array(x_train), np.array(y_train)\n",
    "\n",
    "\n",
    "# Load data into DMatrix object\n",
    "print(x_train.shape, \" is length\")\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dvalidation = xgb.DMatrix(x_test, label=y_test)\n",
    "\n",
    "# Train XGBoost model\n",
    "parameter_dictionary = {}\n",
    "parameter_dictionary[\"objective\"] = \"binary:logitraw\"\n",
    "parameter_dictionary[\"watchlist\"]= dvalidation\n",
    "\n",
    "clf = xgb.XGBRegressor(n_estimators=10000)\n",
    "#we found XGBoost to be more affective than any keras-implemented CNN we tried\n",
    "eval_set  = [(x_train,y_train), (x_test,y_test)]\n",
    "clf.fit(x_train, y_train, eval_set=eval_set, eval_metric=\"mae\")\n",
    "#we use mean absolute error becuase this is a regression problem \n",
    "# Export the classifier to a file\n",
    "model = 'model.bst'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voilà ! A state-of-the-art classifier fit for a novel EEG application, which achieves almost 80% accuracy. Do you think you experience anger, jealousy, or happiness when you see most ads? What makes them more or less effective? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
